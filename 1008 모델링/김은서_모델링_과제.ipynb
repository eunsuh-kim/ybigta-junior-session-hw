{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "766435ef",
   "metadata": {},
   "source": [
    "## 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd4e180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a864a2",
   "metadata": {},
   "source": [
    "## 2. 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da23f5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaf400c",
   "metadata": {},
   "source": [
    "## 3. 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad52ab87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8867b6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15879691",
   "metadata": {},
   "source": [
    "## 4. 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf9dace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.iloc[:,:-1].values\n",
    "y = train.iloc[:,-1].values\n",
    "\n",
    "# Encoding the dependent variable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "\n",
    "# Splitting the dataset into the training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7ead5a",
   "metadata": {},
   "source": [
    "## 5. 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2310bb",
   "metadata": {},
   "source": [
    "### 5-1. LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb8f7a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "f1 score: 0.9017341040462428\n"
     ]
    }
   ],
   "source": [
    "lgb_clf = lgb.LGBMClassifier(objective='binary',\n",
    "                             learning_rate=0.1,\n",
    "                             max_depth=16,\n",
    "                             min_data_in_leaf=200,\n",
    "                             num_leaves=500,\n",
    "                             boosting='gbdt'\n",
    "                            )\n",
    "\n",
    "lgb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lgb_clf.predict(X_test)\n",
    "\n",
    "print('f1 score:', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201fcd7f",
   "metadata": {},
   "source": [
    "LightGBM의 특징\n",
    "\n",
    "장점\n",
    "- 학습하는데 걸리는 시간이 짧다.\n",
    "- 메모리 사용량이 상대적으로 적다.\n",
    "- 대용량 데이터를 처리 가능하다.\n",
    "\n",
    "단점\n",
    "\n",
    "- 적은 데이터셋(10,000건 이하)에서는 과적합이 발생 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a59122",
   "metadata": {},
   "source": [
    "LightGBM 파라미터\n",
    "- learning_rate: 부스팅을 반복할 때의 학습률로, 0~1 사이의 값\n",
    "- max_depth: 트리의 깊이\n",
    "- min_data_in_leaf: 한 리프의 최소 데이터 수\n",
    "- num_leaves: 하나의 트리가 가질 수 있는 최대 리프 개수\n",
    "- boosting: 부스팅 방법\n",
    "- objective: 수치예측이면 regression, 이진분류이면 binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92be55f9",
   "metadata": {},
   "source": [
    "### 5-2. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad03043f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.9017341040462428\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier(max_depth=3, \n",
    "                            n_estimators=500, \n",
    "                            learning_rate=0.1,\n",
    "                            min_child_weight=3,\n",
    "                            gamma=0.2\n",
    "                           )\n",
    "\n",
    "xgb_clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "print('f1 score:', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79abcf58",
   "metadata": {},
   "source": [
    "XGBoost의 특징\n",
    "\n",
    "- GBM 대비 빠른 수행 시간: 병렬 처리로 학습, 분류 속도가 빠르다.\n",
    "- 과적합 규제(Regularization): 표준 GBM의 경우 과적합 규제기능이 없으나, XGBoost는 자체에 과적합 규제 기능으로 강한 내구성이 있다.\n",
    "- 분류와 회귀영역에서 예측 성능이 뛰어나다.\n",
    "- Early Stopping(조기 종료) 기능이 있다.\n",
    "- 다양한 옵션을 제공하며 Customizing이 용이하다.\n",
    "- Missing Values : 결측치를 내부적으로 처리해준다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91e0ee4",
   "metadata": {},
   "source": [
    "XGBoost 파라미터\n",
    "- max_depth: 트리의 최대 깊이\n",
    "- n_estimators: 트리 모델의 개수\n",
    "- learning_rate: 학습 단계별로 이전 결과를 얼마나 반영할지 설정\n",
    "- min_child_weight: child 에서 필요한 모든 관측치에 대한 가중치의 최소합\n",
    "- gamma: 트리에서 추가적으로 가지를 나눌지 말지 결정하는 최소 손실 감소 값, 값을 크게 설정할 수록 과적합이 감소하는 효과가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d2f654",
   "metadata": {},
   "source": [
    "### 5-3. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93050c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.8587570621468926\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(max_depth=5,\n",
    "                               )\n",
    "\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dt_clf.predict(X_test)\n",
    "\n",
    "print('f1_score:', f1_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82417cf",
   "metadata": {},
   "source": [
    "Decision Tree의 특징\n",
    "\n",
    "장점\n",
    "- 데이터의 전처리 (정규화, 결측치, 이상치 등)를 하지 않아도 된다.\n",
    "- 수치형과 범주형 변수를 한꺼번에 다룰 수 있다.\n",
    "\n",
    "단점\n",
    "- 과적합으로 알고리즘 성능이 떨어질 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff5a364",
   "metadata": {},
   "source": [
    "Decision Tree 파라미터\n",
    "- max_depth: 트리의 최대 깊이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c26e82c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
